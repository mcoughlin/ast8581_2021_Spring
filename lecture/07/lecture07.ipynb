{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 04 (Wednesday), AST 8581 / PHYS 8581 / CSCI 8581: Big Data in Astrophysics\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>, Michael Steinbach <stei0062@umn.edu>, Nico Adams adams900@umn.edu\n",
    "\n",
    "\n",
    "With contributions totally ripped off from Gautham Narayan (UIUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Simple MC with uniform sampling of parameter space **does not solve curse of dimensionality (too many useless samples in low likelihood region)** \n",
    "* What if, instead of sampling the parameter space uniformly, you could sample the posterior directly\n",
    "    * Possible outcomes would be **simulated with a frequency proportional to the probability**\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/Likelihood_Surface.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are a couple of approaches to this:\n",
    " \n",
    "### 1. Rejection sampling\n",
    "For this method, we need to define an *envelope function* which everywhere exceeds the target PDF, $p(x)$, and can be sampled. Let this be $Ag(x)$ where $A$ is a scaling factor and $g(x)$ is a PDF we know.\n",
    "\n",
    "Then the algorithm is\n",
    "```\n",
    "while we want more samples\n",
    "    draw a random value for x from some distribution g in the variable x\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= p(x)/(A*g(x)), keep the sample x\n",
    "    otherwise, reject x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visually, this corresponds to drawing points that uniformly fill in the space under $p(x)$.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/mc1_rejection.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "Courtesy: Phil Marshall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# This also does not solve the problem posed by the curse of dimensionality \n",
    "\n",
    "# But this approach is general and works for any function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second approach you've already seen and used a lot:\n",
    "\n",
    "### 2. The Inverse Transform \n",
    "\n",
    "The definition of the CDF (and it's inverse, $F^{-1}$, the **quantile function**). It is called `ppf()` in `scipy.stats`.\n",
    "\n",
    "$F(x) = P(X \\leq x) = \\int_{-\\infty}^x p(x')\\,dx'$\n",
    "\n",
    "By this definition, quantiles of $X$ are uniformly distributed on [0,1]. If $F^{-1}$ is easy to evaluate, we can use this straightforwardly:\n",
    "\n",
    "```\n",
    "draw u from Uniform(0,1)\n",
    "compute x = F_inverse(u)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>PDF<img src=\"figures/mc1_invtrans0.png\" width=100%></td>\n",
    "        <td></td>\n",
    "        <td>CDF<img src=\"figures/mc1_invtrans1.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Courtesy: Phil Marshall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# In class warm-up: The PIT (\"Probability Integral Transform\") with exponential distributions:\n",
    "\n",
    "This distribution has $p(x)=\\lambda e^{-\\lambda x}$ and $F(x)=1-e^{-\\lambda x}$ for $x\\geq0$.\n",
    "\n",
    "The quantile function is, therefore, $F^{-1}(P) = -\\ln(1-P)/\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Here's some code for the inverse tranform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def inv_trans_demo(x, lam):\n",
    "    hist = plt.hist(x, bins=50)\n",
    "    xs = np.linspace(0.0, 10.0/lam, 100)\n",
    "    pdf = lam * np.exp(-lam*xs)\n",
    "    pdfline = plt.plot(xs, pdf, 'r', lw=2)\n",
    "    plt.xlabel(r'x', fontsize=22)\n",
    "    plt.ylabel(r'P(x)', fontsize=22);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for lam = 1., draw a 1000 random samples from a uniform distribution between 0-1 (np.random.rand should do)\n",
    "* use inverse CDF $F^{-1}(P)$ to convert to samples from a exponential distribution\n",
    "* then use the demo code to histogram your samples and overplot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* This does solve the problem posed by the curse of dimensionality \n",
    "\n",
    "* No sample is rejected! \n",
    "\n",
    "* The con is that you have to know what p(x) looks like in advance\n",
    "\n",
    "* If p(x) is your posterior, then you not only need to be able to solve for it analytically (including the evidence - the denominator of Bayes' theorem) but then you've got to figure out how to invert it... even harder.\n",
    "    \n",
    "* There is a place for the PIT, but we started down this road because our functions weren't generally going to be nice, so lets deal with rejection sampling some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# We want a couple of properties\n",
    "\n",
    "* We want to sample the full distribution \n",
    "* We want the frequency of samples between $x$ and $x+dx$ to be proportional to $p(x)dx$\n",
    "\n",
    "What if, instead of drawing i.i.d samples, we drew samples such that they are correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You have already seen examples of processes where samples are correlated with each other - Brownian motion/random walks/Wiener processes - all of these are examples of **stochastic** processes\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/Wiener_process_3d.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " What if we chose our samples to be correlated in a very specific way:\n",
    "   * decide how many samples you want\n",
    "   * start somewhere - we'll call our current position in k-dimensional parameter space $x$\n",
    "   * while you want samples:\n",
    "       * perturb $x$ to $x'$ by some random vector drawn from a fixed distribution   \n",
    "           * i.e. the samples are correlated\n",
    "       * evaluate your function at $x'$ and $x$\n",
    "       * if the function is higher at $x'$ than at $x$ \n",
    "           * then yay! Accept it, and set the position $x'$ to the current position $x$\n",
    "       * else if the function is lower at $x'$ than at $x$\n",
    "           * well maybe that's bad, or maybe we're just unlucky and there's good samples to be had near here\n",
    "           * How do we decide? Well let's draw a random number and check if our function ratio is better or worse\n",
    "               * if it's better, accept and set the position $x'$ to the current position $x$\n",
    "               * else reject and update the current position to be the same \n",
    "       * stick the current position after you did this into a list of samples \n",
    "    \n",
    "This sequence/list of all accepted samples is a **chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is just our **rejection sampling** strategy (recall):\n",
    "\n",
    "```\n",
    "while we want more samples\n",
    "    draw a random value for x from some distribution g in the variable x\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= p(x)/(A*g(x)), keep the sample x\n",
    "    otherwise, reject x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Markov Chains:\n",
    "\n",
    "If we can construct a sequence of samples/chain this way, it will be **ergodic** - i.e. given enough time, the full distribution will be sampled\n",
    "\n",
    "This chain is from some n-dimensional parameter space, with a distribution that is asymptotically proportional to $p(x)$. \n",
    "\n",
    "The constant of proportionality is not important in the first class of problems we will look at. \n",
    "\n",
    "In model comparison problems, the proportionality constant must be known. We've glossed over that so far, so we will blithely push forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With our particular strategy, every n+1 th position on the chain depends **only** on the nth position:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/MarkovChain.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Chains that have this property are called **Markov Chains**.\n",
    "\n",
    "The **state space** of this stochastic process is the set of all possible values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The particular algorithm for generating new samples (more properly detailed in HW4) is called **Metropolis-Hastings** after the folks that came up with it.\n",
    "\n",
    "In summary, the Metropolis-Hastings algorithm consists of these steps:\n",
    "\n",
    "1. given $x$ and $T(x'|x)$, draw a proposed value for $x'$\n",
    "\n",
    "2. compute acceptance probability $p_{\\rm acc}(x,x')$.\n",
    "\n",
    "3. draw a random number between 0 and 1 from a uniform distribution; if it smaller than $p_{\\rm acc}(x,x')$, then accept $x'$.\n",
    "\n",
    "4. if $x'$ is accepted added it to the chain, if not, add $x'$ to the chain.\n",
    "\n",
    "See below for why it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How far should we step (small steps in parameter space or large). This impacts the efficiency of the process but not if we will reach equilibrium.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/sampling.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHY DOES Metropolis-Hastings work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This process is NOT **stationary**. \n",
    "\n",
    "#### Why does it work?\n",
    "The probability of an arbitrary point from such a chain being located at $x'$ is (marginalizing over the possible immediately preceding points)\n",
    "\n",
    "## $$p(x') = \\int dx \\, p(x) \\, T(x'|x)$$\n",
    "\n",
    "where $T(x'|x)$ is the transition probability of a step from $x$ to $x'$.\n",
    "\n",
    "If we have detailed balance, \n",
    "\n",
    "## $$p(x)T(x'|x) = p(x')T(x|x')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "rearranging:\n",
    "\n",
    "## $$ \\frac{T(x'|x)}{T(x|x')} = \\frac{p(x')}{p(x)} $$\n",
    "\n",
    "The basic trick to connect this with rejection sampling is to break the transition into two steps:\n",
    "1. A proposal, g(x'| x)\n",
    "and \n",
    "2. Acceptance ratio, A(x'|x)\n",
    "\n",
    "i.e. \n",
    "\n",
    "## $$ T(x'|x) = A(x'|x) g(x'| x) $$ \n",
    "\n",
    "rearranging again :\n",
    "\n",
    "## $$ \\frac{A(x'|x)}{A(x|x')} = \\frac{p(x')g(x|x')}{p(x)g(x'|x) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that the probability of accepting a step  (once it's proposed) is\n",
    "\n",
    "## $$A(x',x) = \\mathrm{min}\\left[1, \\frac{p(x')g(x|x')}{p(x)g(x'|x)}\\right]$$\n",
    "\n",
    "Let's look again at the requirement of detailed balance\n",
    "\n",
    "> the probability of being at $x$ and moving to $y$ must equal the probability of being at $x'$ and moving to $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first of these is $p(x)g(x'|x)A(x',x)$, where\n",
    "\n",
    "* $p(x)$ is the posterior density (probability of *being* at $x$, if we're sampling $P$ properly)\n",
    "\n",
    "* $g(x'|x)$ is the proposal distribution (probability of attempting a move to $x'$ from $x$)\n",
    "\n",
    "* $A(x',x)$ is the probability of accepting the proposed move\n",
    "\n",
    "With this definition of $A$, detailed balance is automatically satisfied!\n",
    "\n",
    "## $$p(x)g(x'|x)A(x',x) \\equiv p(x')g(x|x')A(x,x')$$\n",
    "\n",
    "Note that **even if a step is rejected, we still keep a sample** (the original state, without moving). The difficulty of finding a temptingly better point is important information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speeding things up\n",
    "\n",
    "Broadly speaking, we can try to\n",
    "1. tailor algorithms to specific classes of PDF\n",
    "2. look for ways to make the general samplers more intelligent\n",
    "\n",
    "We can also use different samplers for different subsets of parameters - the only rule is that every parameter must get updated somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gibbs Sampling\n",
    "is a specialization of Metropolis-Hastings:\n",
    "* Instead of making a general proposal in all dimensions, we cycle through the parameters proposing changes to **one at a time**\n",
    "* A proposal for $\\theta_i$ is into the **fully conditional posterior** $p(\\theta_i|\\theta_{-i},x)$, where $-i$ means all subscripts other than $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gibbs sampling:\n",
    "```\n",
    "while we want more samples\n",
    "    propose theta1 | theta2, theta3, ..., data\n",
    "    accept/reject theta1\n",
    "    propose theta2 | theta1, theta3, ..., data\n",
    "    accept/reject theta2\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: normal PDF\n",
    "\n",
    "25 Metropolis iterations (left) vs. 25 Gibbs transitions (right)\n",
    "\n",
    "Color goes blue$\\rightarrow$red with time (step number)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"figures/mc2_metro.png\" width=100%>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            <img src=\"figures/mc2_gibbs.png\" width=100%>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, this is not obviously an improvement to proposing changes to all $\\theta$ simultaneously.\n",
    "\n",
    "Why is a random drunk walking in one specific direction at a time better than just taking a random step???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Something interesting happens if the fully conditional likelihood and prior are **conjugate** \n",
    "\n",
    "For some likelihood functions, if you choose a certain prior, *the posterior ends up being in the same distribution as the prior.* Such a prior then is called a **Conjugate Prior.**\n",
    "\n",
    "i.e. \n",
    "\n",
    "# $$ P(\\theta) \\mathrm{\\; such\\; that\\; } P(\\theta|D) = P(\\theta) $$\n",
    "\n",
    "\n",
    "i.e. we know the conditional posterior exactly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we use independent samples of the conditional posterior as proposals, then the Metropolis-Hastings acceptance ratio becomes\n",
    "\n",
    "## $$\\frac{p(x')g(x|x')}{p(x)g(x'|x)} = \\frac{p(x')p(x)}{p(x)p(x')} = 1$$\n",
    "\n",
    "**and every proposal is automatically accepted!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Conjugate Gibbs Sampling:\n",
    "```\n",
    "while we want more samples\n",
    "    draw th1 from p(th1|th2,th3,...,data)\n",
    "    draw th2 from p(th2|th1,th3,...,data)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Beta posterior\n",
    "\n",
    "    * Beta prior * Bernoulli likelihood → Beta posterior\n",
    "    * Beta prior * Binomial likelihood → Beta posterior\n",
    "    * Beta prior * Negative Binomial likelihood → Beta posterior\n",
    "    * Beta prior * Geometric likelihood → Beta posterior\n",
    "\n",
    "* Gamma posterior\n",
    "   * Gamma prior * Poisson likelihood → Gamma posterior\n",
    "   * Gamma prior * Exponential likelihood → Gamma posterior\n",
    "\n",
    "* Normal posterior\n",
    "    * Normal prior * Normal likelihood (mean) → Normal posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gibbs Sampling Pros:\n",
    "* No cycles \"wasted\" on rejected proposals\n",
    "* No pesky tuning of the proposal scale\n",
    "\n",
    "Gibbs Sampling Cons:    \n",
    "* Only works for conjugate or partially conjugate models (hence must choose conjugate priors)\n",
    "* Occasionally still slower than proposing multi-parameter Metropolis updates (e.g. when degeneracies are strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some multiple modes:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Some spectral model<br>\n",
    "            <img src=\"figures/mc2_multimode_eg2.png\" width=100%>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            The eggbox function<br>\n",
    "            <img src=\"figures/mc2_eggbox.png\" width=100%>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In these cases, when we were talking about optimizers (as opposed to samplers) that used gradient descent, we found that local optimizers got stuck\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Some spectral model<br>\n",
    "            <img src=\"figures/global_vs_local.png\" width=100%>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "We talked about **simulated annealing** and **basin hopping** as examples of *global optimizers* that can get out of these local minima.\n",
    "\n",
    "With MH, you'd have to make a large step size, but that has a major downside - your acceptance ratio goes down and your \"autocorrelation time\" goes up. (A long autocorrelation time means that, if the algorithm leaves a region, it is unlikely to return back for a long time.)\n",
    "\n",
    "So, it's reasonable to ask if there's an analog for MCMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tempering\n",
    "Consider the function $[p(x)]^{1/T}$, where $p(x)$ is the target PDF.\n",
    "* We say a chain sampling this function has temperature $T$. For $T>1$, $p^{1/T}$ is smoothed out compared with $p$.\n",
    "    * This is the same sort of thing that we saw with **simulated annealing** - start with sampling at a high temperature and then gradually lower the temperature with some schedule\n",
    "* This allows chains to move among multiple peaks more easily.\n",
    "* Of course, we're only actually interested in $T=1$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel tempering\n",
    "\n",
    "With parallel tempering, we run one chain with $T=1$ and several more chains with $T>1$. A modified Metropolis-Hastings update occasionally allows the chains to exchange positions, giving the $T=1$ chain a mechanism for sampling regions of parameter space it might otherwise have low probability of proposing. Samples from the $T=1$ chain can be used for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coping with multiple modes\n",
    "\n",
    "Multiple, well separated posterior modes are a serious challenge for many samplers.\n",
    "* In general, the only way to discover that they exist is by exploring the parameter space with many widely dispersed chains.\n",
    "* To do inference, our chains need to be able to efficiently transition between modes - so far the most reliable general method we've seen for this is parallel tempering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementations of other samplers that are commonly used in research:\n",
    "\n",
    "1. Gibbs Sampling ([pymc3](https://docs.pymc.io/))\n",
    "2. Parallel Tempering (now in [ptemcee](https://pypi.org/project/ptemcee/))\n",
    "3. Hamiltonian Monte Carlo/No U-turn Sampling (also [pymc3](https://docs.pymc.io/))\n",
    "\n",
    "And this is also a sampler, but is not actually a Markov Chain method (Monte Carlo is logically separate from Markov Chain Monte Carlo)\n",
    "4. Nested Sampling ([dynesty](https://dynesty.readthedocs.io/en/latest/index.html) or [Multinest](https://johannesbuchner.github.io/PyMultiNest/))\n",
    "\n",
    "\n",
    "We can't cover all of these, but you should have a good idea on how to start with any of them by now, and which one to pick for a particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In Class Exercise: think\n",
    "\n",
    "Recall the ugly PDF features we were motivated by, namely strong/nonlinear degeneracies and multiple modes.\n",
    "For each of the methods above, do you expect an improvement compared with standard Metropolis in these situations. \n",
    "\n",
    "Why and for which methods?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"figures/mc2_rosenbrock.png\" width=80%>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            <img src=\"figures/mc2_eggbox.png\" width=80%>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In Class Exercise:\n",
    "\n",
    "Here are some simple functions. Use my MH sampling code to sample them, and compare to what you get on a grid of x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Rosenbrock_lnP(x, y, a=1.0, b=100.0):\n",
    "    if y < 0.0: return -np.inf\n",
    "    return -( (a-x)**2 + b*(y-x**2)**2 )\n",
    "\n",
    "def eggbox_lnP(x, y):\n",
    "    return (2.0 + np.cos(0.5*x)*np.cos(0.5*y))**3\n",
    "\n",
    "def sphshell_lnP(x, y, s=0.1):\n",
    "    return -(np.sqrt(x**2+y**2) - 1)**2/(2.0*s**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def metropolis_hastings(p, x0, sigma, *args, nsamp=1000):\n",
    "    \n",
    "    ndim = len(x0)\n",
    "    try:\n",
    "        test_val = p(*x0, *args)\n",
    "        if not np.isfinite(test_val):\n",
    "            raise ValueError('Function at starting position is not finite')\n",
    "        \n",
    "        if test_val == 0.:\n",
    "             raise ValueError('Function at starting position must be non-zero')\n",
    "                \n",
    "    except Exception as e:\n",
    "        message = f'{e}\\nCannot initialize sampler at this position'\n",
    "        raise ValueError(message)\n",
    "    \n",
    "        \n",
    "    # we need something to save the samples we want\n",
    "    samples = np.zeros((nsamp, ndim))    \n",
    "\n",
    "    x = np.array(x0)\n",
    "    sigma = np.array(sigma)\n",
    "    \n",
    "    # the position and step size arrays had better be the same \n",
    "    assert x.shape == sigma.shape, 'Shape of x and shape of sigma must be the same'\n",
    "    \n",
    "    # while we want more samples\n",
    "    for i in range(nsamp):\n",
    "\n",
    "        # now we adjust the initial position a little\n",
    "        # instead of explictly definition g(x|x') and g(x'|x)\n",
    "        # we can recognize that a Gaussian is a stationary kernel\n",
    "        # as we discussed in class, this is nice because \n",
    "        # all that matters is the absolute difference between x' and x\n",
    "        # and if that's the case, then g(x'|x) = g(x|x')\n",
    "        x_prime = x + sigma*np.random.randn(ndim)\n",
    "\n",
    "\n",
    "        if np.random.rand() < (p(*x_prime, *args) / p(*x, *args)):\n",
    "            x = x_prime\n",
    "            \n",
    "        # we save the sample to the chain\n",
    "        samples[i] = x\n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mh_demo(p, x0, sigma, nsamp=1000):\n",
    "    samples = metropolis_hastings(p, x0, sigma, nsamp=nsamp)\n",
    "\n",
    "    \n",
    "    # create some axes\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    ax0, ax1, ax2 = axs\n",
    "    \n",
    "    # plot all the data in grey\n",
    "    ax0.scatter(samples[:, 0], samples[:, 1], color='grey', alpha=0.1, marker='.')\n",
    "    ax1.plot(samples[:, 0], marker='.', color='grey', alpha=0.1, ls='-')\n",
    "    ax2.plot(samples[:, 1], marker='.', color='grey', alpha=0.1, ls='-')\n",
    "    return fig\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
